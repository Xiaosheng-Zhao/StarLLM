/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
Global seed set to 42
wandb: Currently logged in as: xiaosheng_zhao. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /scratch/zxs/scripts/starllm/back2/AstroCLIP/astroclip/outputs/wandb/run-20240716_173648-9gj1ewke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-bush-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaosheng_zhao/astroclip-alignment
wandb: üöÄ View run at https://wandb.ai/xiaosheng_zhao/astroclip-alignment/runs/9gj1ewke
/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:263: UserWarning: Attribute 'image_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['image_encoder'])`.
  rank_zero_warn(
/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:263: UserWarning: Attribute 'spectrum_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['spectrum_encoder'])`.
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [9]

  | Name             | Type         | Params
--------------------------------------------------
0 | image_encoder    | ImageHead    | 55.2 M
1 | spectrum_encoder | SpectrumHead | 55.2 M
2 | criterion        | CLIPLoss     | 0     
--------------------------------------------------
24.1 M    Trainable params
86.4 M    Non-trainable params
110 M     Total params
441.989   Total estimated model params size (MB)
Sanity Checking: 0it [00:00, ?it/s]/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/lightning/pytorch/utilities/data.py:110: UserWarning: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.
  rank_zero_warn(
                                   /home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s] Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:54<01:48, 54.12s/it]Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:54<01:48, 54.12s/it, loss=5.56, v_num=ewke]Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:55<00:27, 27.94s/it, loss=5.56, v_num=ewke]Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:55<00:27, 27.94s/it, loss=5.56, v_num=ewke]Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:57<00:00, 19.21s/it, loss=5.56, v_num=ewke]Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:57<00:00, 19.21s/it, loss=5.56, v_num=ewke]Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:57<00:00, 19.21s/it, loss=5.56, v_num=ewke]/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:360: UserWarning: `ModelCheckpoint(monitor='val_loss_nologit')` could not find the monitored key in the returned metrics: ['train_loss_withlogit', 'train_loss_nologit', 'scale', 'epoch', 'step']. HINT: Did you call `log('val_loss_nologit', value)` in the `LightningModule`?
  warning_cache.warn(m)
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.56, v_num=ewke]        Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.56, v_num=ewke]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:34<01:08, 34.22s/it, loss=5.56, v_num=ewke]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:34<01:08, 34.22s/it, loss=5.56, v_num=ewke]Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:51<00:25, 25.67s/it, loss=5.56, v_num=ewke]Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:51<00:25, 25.67s/it, loss=5.56, v_num=ewke]Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:53<00:00, 17.70s/it, loss=5.56, v_num=ewke]Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:53<00:00, 17.70s/it, loss=5.56, v_num=ewke]Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:53<00:00, 17.70s/it, loss=5.56, v_num=ewke]Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.56, v_num=ewke]        Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.56, v_num=ewke]Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:33<01:07, 33.58s/it, loss=5.56, v_num=ewke]Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:33<01:07, 33.59s/it, loss=5.56, v_num=ewke]Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:46<00:23, 23.18s/it, loss=5.56, v_num=ewke]Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:46<00:23, 23.18s/it, loss=5.56, v_num=ewke]Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:50<00:00, 16.94s/it, loss=5.56, v_num=ewke]Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:50<00:00, 16.94s/it, loss=5.56, v_num=ewke]Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:50<00:00, 16.94s/it, loss=5.56, v_num=ewke]Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.56, v_num=ewke]        Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.56, v_num=ewke]Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:52<01:44, 52.19s/it, loss=5.56, v_num=ewke]Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:52<01:44, 52.20s/it, loss=5.56, v_num=ewke]Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:53<00:26, 26.97s/it, loss=5.56, v_num=ewke]Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:53<00:26, 26.97s/it, loss=5.56, v_num=ewke]Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:55<00:00, 18.57s/it, loss=5.56, v_num=ewke]Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:55<00:00, 18.57s/it, loss=5.55, v_num=ewke]Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:55<00:00, 18.57s/it, loss=5.55, v_num=ewke]Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.55, v_num=ewke]        Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.55, v_num=ewke]Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:52<01:44, 52.21s/it, loss=5.55, v_num=ewke]Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:52<01:44, 52.22s/it, loss=5.55, v_num=ewke]Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:53<00:26, 26.99s/it, loss=5.55, v_num=ewke]Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:53<00:26, 26.99s/it, loss=5.55, v_num=ewke]Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:55<00:00, 18.58s/it, loss=5.55, v_num=ewke]Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:55<00:00, 18.58s/it, loss=5.55, v_num=ewke]Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:55<00:00, 18.58s/it, loss=5.55, v_num=ewke]Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.55, v_num=ewke]        Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.55, v_num=ewke]Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:49<01:38, 49.19s/it, loss=5.55, v_num=ewke]Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:49<01:38, 49.19s/it, loss=5.55, v_num=ewke]Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:50<00:25, 25.47s/it, loss=5.55, v_num=ewke]Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:50<00:25, 25.47s/it, loss=5.55, v_num=ewke]Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:52<00:00, 17.57s/it, loss=5.55, v_num=ewke]Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:52<00:00, 17.57s/it, loss=5.55, v_num=ewke]Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:52<00:00, 17.57s/it, loss=5.55, v_num=ewke]Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.55, v_num=ewke]        Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.55, v_num=ewke]Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:43<01:27, 43.97s/it, loss=5.55, v_num=ewke]Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:43<01:27, 43.97s/it, loss=5.55, v_num=ewke]Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:48<00:24, 24.06s/it, loss=5.55, v_num=ewke]Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:48<00:24, 24.06s/it, loss=5.55, v_num=ewke]Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:49<00:00, 16.62s/it, loss=5.55, v_num=ewke]Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:49<00:00, 16.62s/it, loss=5.55, v_num=ewke]Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:49<00:00, 16.63s/it, loss=5.55, v_num=ewke]Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.55, v_num=ewke]        Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.55, v_num=ewke]Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:48<01:37, 48.99s/it, loss=5.55, v_num=ewke]Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:48<01:37, 48.99s/it, loss=5.55, v_num=ewke]Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:50<00:25, 25.37s/it, loss=5.55, v_num=ewke]Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:50<00:25, 25.37s/it, loss=5.55, v_num=ewke]Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:52<00:00, 17.50s/it, loss=5.55, v_num=ewke]Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:52<00:00, 17.50s/it, loss=5.55, v_num=ewke]Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:52<00:00, 17.50s/it, loss=5.55, v_num=ewke]Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.55, v_num=ewke]        Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s, loss=5.55, v_num=ewke]=>> PBS: job killed: ncpus 2.56 exceeded limit 2 (sum)
