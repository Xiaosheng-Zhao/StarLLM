/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
Global seed set to 42
wandb: Currently logged in as: xiaosheng_zhao. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /scratch/zxs/scripts/starllm/back2/AstroCLIP/astroclip/outputs/wandb/run-20240716_165643-8j7f9ja2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sponge-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaosheng_zhao/astroclip-spectrum
wandb: üöÄ View run at https://wandb.ai/xiaosheng_zhao/astroclip-spectrum/runs/8j7f9ja2
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [9]

  | Name            | Type       | Params
-----------------------------------------------
0 | data_embed      | Linear     | 17.7 K
1 | position_embed  | Embedding  | 614 K 
2 | dropout         | Dropout    | 0     
3 | blocks          | ModuleList | 42.5 M
4 | final_layernorm | LayerNorm  | 1.5 K 
5 | head            | Linear     | 16.9 K
-----------------------------------------------
43.2 M    Trainable params
0         Non-trainable params
43.2 M    Total params
172.711   Total estimated model params size (MB)
Sanity Checking: 0it [00:00, ?it/s]/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]torch.Size([64, 391, 22])
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s]                                                                           /home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/zxs/.conda/envs/starllm2/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/16 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/16 [00:00<?, ?it/s] torch.Size([64, 391, 22])
Epoch 0:   6%|‚ñã         | 1/16 [00:03<00:57,  3.87s/it]Epoch 0:   6%|‚ñã         | 1/16 [00:03<00:58,  3.87s/it, loss=2.43, v_num=9ja2, training_loss=2.430]torch.Size([64, 391, 22])
Epoch 0:  12%|‚ñà‚ñé        | 2/16 [00:08<00:56,  4.04s/it, loss=2.43, v_num=9ja2, training_loss=2.430]Epoch 0:  12%|‚ñà‚ñé        | 2/16 [00:08<00:56,  4.04s/it, loss=2.45, v_num=9ja2, training_loss=2.460]torch.Size([64, 391, 22])
Epoch 0:  19%|‚ñà‚ñâ        | 3/16 [00:12<00:53,  4.10s/it, loss=2.45, v_num=9ja2, training_loss=2.460]Epoch 0:  19%|‚ñà‚ñâ        | 3/16 [00:12<00:53,  4.10s/it, loss=2.07, v_num=9ja2, training_loss=1.320]torch.Size([64, 391, 22])
Epoch 0:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:16<00:50,  4.18s/it, loss=2.07, v_num=9ja2, training_loss=1.320]Epoch 0:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:16<00:50,  4.18s/it, loss=1.91, v_num=9ja2, training_loss=1.420]torch.Size([64, 391, 22])
Epoch 0:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:20<00:45,  4.17s/it, loss=1.91, v_num=9ja2, training_loss=1.420]Epoch 0:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:20<00:45,  4.17s/it, loss=1.93, v_num=9ja2, training_loss=2.030]torch.Size([64, 391, 22])
Epoch 0:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:25<00:41,  4.19s/it, loss=1.93, v_num=9ja2, training_loss=2.030]Epoch 0:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:25<00:41,  4.19s/it, loss=1.94, v_num=9ja2, training_loss=1.970]torch.Size([64, 391, 22])
Epoch 0:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:29<00:37,  4.19s/it, loss=1.94, v_num=9ja2, training_loss=1.970]Epoch 0:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:29<00:37,  4.19s/it, loss=1.89, v_num=9ja2, training_loss=1.600]torch.Size([64, 391, 22])
Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:33<00:33,  4.21s/it, loss=1.89, v_num=9ja2, training_loss=1.600]Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:33<00:33,  4.21s/it, loss=1.81, v_num=9ja2, training_loss=1.270]torch.Size([64, 391, 22])
Epoch 0:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:37<00:29,  4.20s/it, loss=1.81, v_num=9ja2, training_loss=1.270]Epoch 0:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:37<00:29,  4.20s/it, loss=1.72, v_num=9ja2, training_loss=0.941]torch.Size([64, 391, 22])
Epoch 0:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:42<00:25,  4.21s/it, loss=1.72, v_num=9ja2, training_loss=0.941]Epoch 0:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:42<00:25,  4.21s/it, loss=1.64, v_num=9ja2, training_loss=0.988]torch.Size([64, 391, 22])
Epoch 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:46<00:20,  4.20s/it, loss=1.64, v_num=9ja2, training_loss=0.988]Epoch 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:46<00:20,  4.20s/it, loss=1.59, v_num=9ja2, training_loss=1.040]torch.Size([64, 391, 22])
Epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:50<00:16,  4.21s/it, loss=1.59, v_num=9ja2, training_loss=1.040]Epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:50<00:16,  4.21s/it, loss=1.54, v_num=9ja2, training_loss=1.060]torch.Size([64, 391, 22])
Epoch 0:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:54<00:12,  4.20s/it, loss=1.54, v_num=9ja2, training_loss=1.060]Epoch 0:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:54<00:12,  4.20s/it, loss=1.51, v_num=9ja2, training_loss=1.040]torch.Size([64, 391, 22])
Epoch 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:58<00:08,  4.21s/it, loss=1.51, v_num=9ja2, training_loss=1.040]Epoch 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:58<00:08,  4.21s/it, loss=1.47, v_num=9ja2, training_loss=1.000]torch.Size([64, 391, 22])
Epoch 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [01:03<00:04,  4.20s/it, loss=1.47, v_num=9ja2, training_loss=1.000]Epoch 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [01:03<00:04,  4.20s/it, loss=1.43, v_num=9ja2, training_loss=0.931]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][Atorch.Size([64, 391, 22])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 62.97it/s][AEpoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:06<00:00,  4.15s/it, loss=1.43, v_num=9ja2, training_loss=0.931]Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:06<00:00,  4.17s/it, loss=1.43, v_num=9ja2, training_loss=0.931, val_training_loss=0.966]
                                                                      [AEpoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:06<00:00,  4.17s/it, loss=1.43, v_num=9ja2, training_loss=0.931, val_training_loss=0.966]Epoch 0:   0%|          | 0/16 [00:00<?, ?it/s, loss=1.43, v_num=9ja2, training_loss=0.931, val_training_loss=0.966]         Epoch 1:   0%|          | 0/16 [00:00<?, ?it/s, loss=1.43, v_num=9ja2, training_loss=0.931, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:   6%|‚ñã         | 1/16 [00:04<01:04,  4.31s/it, loss=1.43, v_num=9ja2, training_loss=0.931, val_training_loss=0.966]Epoch 1:   6%|‚ñã         | 1/16 [00:04<01:04,  4.31s/it, loss=1.4, v_num=9ja2, training_loss=0.900, val_training_loss=0.966] torch.Size([64, 391, 22])
Epoch 1:  12%|‚ñà‚ñé        | 2/16 [00:08<00:58,  4.20s/it, loss=1.4, v_num=9ja2, training_loss=0.900, val_training_loss=0.966]Epoch 1:  12%|‚ñà‚ñé        | 2/16 [00:08<00:58,  4.20s/it, loss=1.38, v_num=9ja2, training_loss=0.970, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  19%|‚ñà‚ñâ        | 3/16 [00:12<00:54,  4.23s/it, loss=1.38, v_num=9ja2, training_loss=0.970, val_training_loss=0.966]Epoch 1:  19%|‚ñà‚ñâ        | 3/16 [00:12<00:54,  4.23s/it, loss=1.35, v_num=9ja2, training_loss=0.915, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:16<00:50,  4.18s/it, loss=1.35, v_num=9ja2, training_loss=0.915, val_training_loss=0.966]Epoch 1:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:16<00:50,  4.18s/it, loss=1.33, v_num=9ja2, training_loss=0.943, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:21<00:46,  4.20s/it, loss=1.33, v_num=9ja2, training_loss=0.943, val_training_loss=0.966]Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:21<00:46,  4.20s/it, loss=1.31, v_num=9ja2, training_loss=0.893, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:25<00:41,  4.18s/it, loss=1.31, v_num=9ja2, training_loss=0.893, val_training_loss=0.966]Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:25<00:41,  4.18s/it, loss=1.23, v_num=9ja2, training_loss=0.909, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:29<00:37,  4.19s/it, loss=1.23, v_num=9ja2, training_loss=0.909, val_training_loss=0.966]Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:29<00:37,  4.19s/it, loss=1.15, v_num=9ja2, training_loss=0.934, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:33<00:33,  4.17s/it, loss=1.15, v_num=9ja2, training_loss=0.934, val_training_loss=0.966]Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:33<00:33,  4.17s/it, loss=1.14, v_num=9ja2, training_loss=0.958, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:37<00:29,  4.16s/it, loss=1.14, v_num=9ja2, training_loss=0.958, val_training_loss=0.966]Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:37<00:29,  4.16s/it, loss=1.11, v_num=9ja2, training_loss=0.951, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:41<00:24,  4.11s/it, loss=1.11, v_num=9ja2, training_loss=0.951, val_training_loss=0.966]Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:41<00:24,  4.11s/it, loss=1.05, v_num=9ja2, training_loss=0.876, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:45<00:20,  4.10s/it, loss=1.05, v_num=9ja2, training_loss=0.876, val_training_loss=0.966]Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:45<00:20,  4.10s/it, loss=1, v_num=9ja2, training_loss=0.901, val_training_loss=0.966]   torch.Size([64, 391, 22])
Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:49<00:16,  4.08s/it, loss=1, v_num=9ja2, training_loss=0.901, val_training_loss=0.966]Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:49<00:16,  4.09s/it, loss=0.966, v_num=9ja2, training_loss=0.911, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:53<00:12,  4.11s/it, loss=0.966, v_num=9ja2, training_loss=0.911, val_training_loss=0.966]Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:53<00:12,  4.11s/it, loss=0.947, v_num=9ja2, training_loss=0.874, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:58<00:08,  4.15s/it, loss=0.947, v_num=9ja2, training_loss=0.874, val_training_loss=0.966]Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:58<00:08,  4.15s/it, loss=0.944, v_num=9ja2, training_loss=0.893, val_training_loss=0.966]torch.Size([64, 391, 22])
Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [01:02<00:04,  4.17s/it, loss=0.944, v_num=9ja2, training_loss=0.893, val_training_loss=0.966]Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [01:02<00:04,  4.17s/it, loss=0.939, v_num=9ja2, training_loss=0.874, val_training_loss=0.966]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][Atorch.Size([64, 391, 22])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 56.34it/s][AEpoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:06<00:00,  4.14s/it, loss=0.939, v_num=9ja2, training_loss=0.874, val_training_loss=0.966]Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:06<00:00,  4.15s/it, loss=0.939, v_num=9ja2, training_loss=0.874, val_training_loss=0.934]
                                                                      [AEpoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:06<00:00,  4.15s/it, loss=0.939, v_num=9ja2, training_loss=0.874, val_training_loss=0.934]Epoch 1:   0%|          | 0/16 [00:00<?, ?it/s, loss=0.939, v_num=9ja2, training_loss=0.874, val_training_loss=0.934]         Epoch 2:   0%|          | 0/16 [00:00<?, ?it/s, loss=0.939, v_num=9ja2, training_loss=0.874, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:   6%|‚ñã         | 1/16 [00:04<01:03,  4.25s/it, loss=0.939, v_num=9ja2, training_loss=0.874, val_training_loss=0.934]Epoch 2:   6%|‚ñã         | 1/16 [00:04<01:03,  4.26s/it, loss=0.93, v_num=9ja2, training_loss=0.868, val_training_loss=0.934] torch.Size([64, 391, 22])
Epoch 2:  12%|‚ñà‚ñé        | 2/16 [00:08<01:01,  4.39s/it, loss=0.93, v_num=9ja2, training_loss=0.868, val_training_loss=0.934]Epoch 2:  12%|‚ñà‚ñé        | 2/16 [00:08<01:01,  4.40s/it, loss=0.92, v_num=9ja2, training_loss=0.848, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  19%|‚ñà‚ñâ        | 3/16 [00:13<00:56,  4.35s/it, loss=0.92, v_num=9ja2, training_loss=0.848, val_training_loss=0.934]Epoch 2:  19%|‚ñà‚ñâ        | 3/16 [00:13<00:56,  4.35s/it, loss=0.91, v_num=9ja2, training_loss=0.850, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:17<00:52,  4.37s/it, loss=0.91, v_num=9ja2, training_loss=0.850, val_training_loss=0.934]Epoch 2:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:17<00:52,  4.37s/it, loss=0.904, v_num=9ja2, training_loss=0.878, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:21<00:47,  4.34s/it, loss=0.904, v_num=9ja2, training_loss=0.878, val_training_loss=0.934]Epoch 2:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:21<00:47,  4.34s/it, loss=0.901, v_num=9ja2, training_loss=0.879, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:26<00:43,  4.36s/it, loss=0.901, v_num=9ja2, training_loss=0.879, val_training_loss=0.934]Epoch 2:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:26<00:43,  4.36s/it, loss=0.9, v_num=9ja2, training_loss=0.873, val_training_loss=0.934]  torch.Size([64, 391, 22])
Epoch 2:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:30<00:39,  4.35s/it, loss=0.9, v_num=9ja2, training_loss=0.873, val_training_loss=0.934]Epoch 2:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:30<00:39,  4.35s/it, loss=0.895, v_num=9ja2, training_loss=0.875, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:34<00:34,  4.37s/it, loss=0.895, v_num=9ja2, training_loss=0.875, val_training_loss=0.934]Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:34<00:34,  4.37s/it, loss=0.893, v_num=9ja2, training_loss=0.871, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:39<00:30,  4.36s/it, loss=0.893, v_num=9ja2, training_loss=0.871, val_training_loss=0.934]Epoch 2:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:39<00:30,  4.36s/it, loss=0.889, v_num=9ja2, training_loss=0.862, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:43<00:26,  4.38s/it, loss=0.889, v_num=9ja2, training_loss=0.862, val_training_loss=0.934]Epoch 2:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:43<00:26,  4.38s/it, loss=0.887, v_num=9ja2, training_loss=0.848, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:48<00:21,  4.37s/it, loss=0.887, v_num=9ja2, training_loss=0.848, val_training_loss=0.934]Epoch 2:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:48<00:21,  4.37s/it, loss=0.887, v_num=9ja2, training_loss=0.919, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:52<00:17,  4.37s/it, loss=0.887, v_num=9ja2, training_loss=0.919, val_training_loss=0.934]Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:52<00:17,  4.37s/it, loss=0.882, v_num=9ja2, training_loss=0.826, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:56<00:13,  4.36s/it, loss=0.882, v_num=9ja2, training_loss=0.826, val_training_loss=0.934]Epoch 2:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:56<00:13,  4.36s/it, loss=0.876, v_num=9ja2, training_loss=0.837, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [01:01<00:08,  4.36s/it, loss=0.876, v_num=9ja2, training_loss=0.837, val_training_loss=0.934]Epoch 2:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [01:01<00:08,  4.36s/it, loss=0.873, v_num=9ja2, training_loss=0.898, val_training_loss=0.934]torch.Size([64, 391, 22])
Epoch 2:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [01:05<00:04,  4.35s/it, loss=0.873, v_num=9ja2, training_loss=0.898, val_training_loss=0.934]Epoch 2:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [01:05<00:04,  4.35s/it, loss=0.871, v_num=9ja2, training_loss=0.841, val_training_loss=0.934]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][Atorch.Size([64, 391, 22])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 56.99it/s][AEpoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:08<00:00,  4.30s/it, loss=0.871, v_num=9ja2, training_loss=0.841, val_training_loss=0.934]Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:09<00:00,  4.32s/it, loss=0.871, v_num=9ja2, training_loss=0.841, val_training_loss=0.849]
                                                                      [AEpoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:09<00:00,  4.32s/it, loss=0.871, v_num=9ja2, training_loss=0.841, val_training_loss=0.849]Epoch 2:   0%|          | 0/16 [00:00<?, ?it/s, loss=0.871, v_num=9ja2, training_loss=0.841, val_training_loss=0.849]         Epoch 3:   0%|          | 0/16 [00:00<?, ?it/s, loss=0.871, v_num=9ja2, training_loss=0.841, val_training_loss=0.849]torch.Size([64, 391, 22])
Epoch 3:   6%|‚ñã         | 1/16 [00:08<02:04,  8.33s/it, loss=0.871, v_num=9ja2, training_loss=0.841, val_training_loss=0.849]Epoch 3:   6%|‚ñã         | 1/16 [00:08<02:04,  8.33s/it, loss=0.871, v_num=9ja2, training_loss=0.893, val_training_loss=0.849]torch.Size([64, 391, 22])
Epoch 3:  12%|‚ñà‚ñé        | 2/16 [00:16<01:54,  8.16s/it, loss=0.871, v_num=9ja2, training_loss=0.893, val_training_loss=0.849]Epoch 3:  12%|‚ñà‚ñé        | 2/16 [00:16<01:54,  8.17s/it, loss=0.871, v_num=9ja2, training_loss=0.910, val_training_loss=0.849]torch.Size([64, 391, 22])
Epoch 3:  19%|‚ñà‚ñâ        | 3/16 [00:24<01:47,  8.24s/it, loss=0.871, v_num=9ja2, training_loss=0.910, val_training_loss=0.849]Epoch 3:  19%|‚ñà‚ñâ        | 3/16 [00:24<01:47,  8.24s/it, loss=0.868, v_num=9ja2, training_loss=0.818, val_training_loss=0.849]torch.Size([64, 391, 22])
Epoch 3:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:31<01:34,  7.87s/it, loss=0.868, v_num=9ja2, training_loss=0.818, val_training_loss=0.849]Epoch 3:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:31<01:34,  7.87s/it, loss=0.866, v_num=9ja2, training_loss=0.842, val_training_loss=0.849]torch.Size([64, 391, 22])
Epoch 3:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:38<01:24,  7.66s/it, loss=0.866, v_num=9ja2, training_loss=0.842, val_training_loss=0.849]Epoch 3:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:38<01:24,  7.66s/it, loss=0.866, v_num=9ja2, training_loss=0.882, val_training_loss=0.849]Epoch 3:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:38<01:24,  7.66s/it, loss=0.866, v_num=9ja2, training_loss=0.882, val_training_loss=0.849]`Trainer.fit` stopped: `max_steps=50` reached.
Epoch 3:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:40<01:29,  8.12s/it, loss=0.866, v_num=9ja2, training_loss=0.882, val_training_loss=0.849]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: 
wandb: Run history:
wandb:               epoch ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb:            lr-AdamW ‚ñÅ
wandb: trainer/global_step ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà
wandb:       training_loss ‚ñÅ
wandb:   val_training_loss ‚ñà‚ñÜ‚ñÅ
wandb: 
wandb: Run summary:
wandb:               epoch 3
wandb:            lr-AdamW 0.0
wandb: trainer/global_step 49
wandb:       training_loss 0.88207
wandb:   val_training_loss 0.84859
wandb: 
wandb: üöÄ View run scarlet-sponge-47 at: https://wandb.ai/xiaosheng_zhao/astroclip-spectrum/runs/8j7f9ja2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/xiaosheng_zhao/astroclip-spectrum
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./astroclip/outputs/wandb/run-20240716_165643-8j7f9ja2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
